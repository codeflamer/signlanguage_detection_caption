{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3588e329",
   "metadata": {},
   "source": [
    "# Setup Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b0ed8ff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this path are in a variable for easy access\n",
    "WORKSPACE_PATH = 'Tensorflow/workspace'\n",
    "SCRIPTS_PATH = 'Tensorflow/scripts'\n",
    "APIMODEL_PATH = 'Tensorflow/models/research/object_detection'\n",
    "ANNOTATION_PATH = WORKSPACE_PATH+'/annotations'\n",
    "IMAGE_PATH = WORKSPACE_PATH+'/images'\n",
    "MODEL_PATH = WORKSPACE_PATH+'/models'\n",
    "PRETRAINED_MODEL_PATH = WORKSPACE_PATH+'/pre-trained-models'\n",
    "CONFIG_PATH = MODEL_PATH+'/ssd_mobilenet2/pipeline.config'\n",
    "CHECKPOINT_PATH = MODEL_PATH+'/ssd_mobilenet2/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7045ad3f",
   "metadata": {},
   "source": [
    "# Create Label Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "246fb5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels for all the detection that are going to be identifying from an image or video.\n",
    "labels = [{'name':\"Hello\",'id':1},{'name':\"Thanks\",'id':2},{'name':\"Yes\",'id':3},{'name':\"No\",'id':4},{'name':\"I Love You\",'id':5}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56bd89be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to create a file called, label_map.pbtxt and write to it. This is the format TENSORFLOW MODEL API expects the labels for detection.\n",
    "# item {\n",
    "#     name: name of object to detect\n",
    "#    id: id of the object to detect\n",
    "# }\n",
    "\n",
    "with open(ANNOTATION_PATH+'\\label_map.pbtxt','w') as f:\n",
    "    for label in labels:\n",
    "        f.write('item{\\n')\n",
    "        f.write('\\t name:\\'{}\\'\\n'.format(label[\"name\"]))\n",
    "        f.write('\\t id:{}\\n'.format(label[\"id\"]))\n",
    "        f.write('}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa0a6df2",
   "metadata": {},
   "source": [
    "# Create TF Records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f446e19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/train.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/string_int_label_map.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully created the TFRecord file: Tensorflow/workspace/annotations/test.record\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/string_int_label_map.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Python script to generate train and test record\n",
    "!python {SCRIPTS_PATH+'/generate_tfrecord.py'} -x {IMAGE_PATH+\"/train\"} -l {ANNOTATION_PATH+\"/label_map.pbtxt\"} -o {ANNOTATION_PATH + '/train.record'}\n",
    "\n",
    "!python {SCRIPTS_PATH + '/generate_tfrecord.py'} -x {IMAGE_PATH + '/test'} -l {ANNOTATION_PATH + '/label_map.pbtxt'} -o {ANNOTATION_PATH + '/test.record'}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "696ae7de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Download TF models Pretrained models from tensorflow model Zoo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "686fcd22-2222-4453-b31b-5bfb0cd0bc6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'models'...\n",
      "Updating files:  31% (1205/3871)\n",
      "Updating files:  32% (1239/3871)\n",
      "Updating files:  33% (1278/3871)\n",
      "Updating files:  34% (1317/3871)\n",
      "Updating files:  35% (1355/3871)\n",
      "Updating files:  36% (1394/3871)\n",
      "Updating files:  37% (1433/3871)\n",
      "Updating files:  38% (1471/3871)\n",
      "Updating files:  39% (1510/3871)\n",
      "Updating files:  40% (1549/3871)\n",
      "Updating files:  41% (1588/3871)\n",
      "Updating files:  42% (1626/3871)\n",
      "Updating files:  43% (1665/3871)\n",
      "Updating files:  44% (1704/3871)\n",
      "Updating files:  45% (1742/3871)\n",
      "Updating files:  46% (1781/3871)\n",
      "Updating files:  47% (1820/3871)\n",
      "Updating files:  48% (1859/3871)\n",
      "Updating files:  49% (1897/3871)\n",
      "Updating files:  50% (1936/3871)\n",
      "Updating files:  50% (1951/3871)\n",
      "Updating files:  51% (1975/3871)\n",
      "Updating files:  52% (2013/3871)\n",
      "Updating files:  53% (2052/3871)\n",
      "Updating files:  54% (2091/3871)\n",
      "Updating files:  55% (2130/3871)\n",
      "Updating files:  56% (2168/3871)\n",
      "Updating files:  57% (2207/3871)\n",
      "Updating files:  58% (2246/3871)\n",
      "Updating files:  59% (2284/3871)\n",
      "Updating files:  60% (2323/3871)\n",
      "Updating files:  61% (2362/3871)\n",
      "Updating files:  62% (2401/3871)\n",
      "Updating files:  63% (2439/3871)\n",
      "Updating files:  64% (2478/3871)\n",
      "Updating files:  65% (2517/3871)\n",
      "Updating files:  66% (2555/3871)\n",
      "Updating files:  67% (2594/3871)\n",
      "Updating files:  68% (2633/3871)\n",
      "Updating files:  69% (2671/3871)\n",
      "Updating files:  70% (2710/3871)\n",
      "Updating files:  71% (2749/3871)\n",
      "Updating files:  72% (2788/3871)\n",
      "Updating files:  72% (2793/3871)\n",
      "Updating files:  73% (2826/3871)\n",
      "Updating files:  74% (2865/3871)\n",
      "Updating files:  75% (2904/3871)\n",
      "Updating files:  76% (2942/3871)\n",
      "Updating files:  77% (2981/3871)\n",
      "Updating files:  78% (3020/3871)\n",
      "Updating files:  79% (3059/3871)\n",
      "Updating files:  80% (3097/3871)\n",
      "Updating files:  81% (3136/3871)\n",
      "Updating files:  82% (3175/3871)\n",
      "Updating files:  83% (3213/3871)\n",
      "Updating files:  84% (3252/3871)\n",
      "Updating files:  85% (3291/3871)\n",
      "Updating files:  86% (3330/3871)\n",
      "Updating files:  87% (3368/3871)\n",
      "Updating files:  88% (3407/3871)\n",
      "error: unable to create file research/object_detection/samples/configs/ssd_mobilenet_v2_fpnlite_quantized_shared_box_predictor_256x256_depthmultiplier_75_coco14_sync.config: Filename too long\n",
      "Updating files:  89% (3446/3871)\n",
      "Updating files:  90% (3484/3871)\n",
      "Updating files:  91% (3523/3871)\n",
      "Updating files:  92% (3562/3871)\n",
      "Updating files:  93% (3601/3871)\n",
      "Updating files:  94% (3639/3871)\n",
      "Updating files:  95% (3678/3871)\n",
      "Updating files:  95% (3690/3871)\n",
      "Updating files:  96% (3717/3871)\n",
      "Updating files:  97% (3755/3871)\n",
      "Updating files:  98% (3794/3871)\n",
      "Updating files:  99% (3833/3871)\n",
      "Updating files: 100% (3871/3871)\n",
      "Updating files: 100% (3871/3871), done.\n",
      "fatal: unable to checkout working tree\n",
      "warning: Clone succeeded, but checkout failed.\n",
      "You can inspect what was checked out with 'git status'\n",
      "and retry with 'git restore --source=HEAD :/'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!cd Tensorflow && git clone https://github.com/tensorflow/models.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "40fbe0cc-3df8-4573-bfb7-cb032a1ee733",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/c/Users/emryz/OneDrive/Desktop/ML/computer_Vision/Object_Detection/SignLanguageDetectionAndCaption/Tensorflow/models/research\n"
     ]
    }
   ],
   "source": [
    "## Shell: go into the research folder and confirm the path to the working directory.\n",
    "!cd Tensorflow/models/research && pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "a2d5a191-40f7-4a7d-9b17-bd67abededad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the product from this directory and spill out the corresponding python equivalent\n",
    "!cd Tensorflow/models/research && protoc object_detection/protos/*.proto --python_out=."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "29fff1c6-0803-4771-a39c-7cc2840c9fed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy from setup.py to research\n",
    "!cp Tensorflow/models/research/object_detection/packages/tf2/setup.py Tensorflow/models/research"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49aaf1e9-97f4-48c5-a407-fb13dd38efdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This commmand installs all the package in the setup.py file, These packages are what the model relies on to run seamlessly\n",
    "# For more details refer to TENSORFLOW MODEL API INSTALLATION: https://tensorflow-object-detection-api-tutorial.readthedocs.io/en/latest/install.html#tf-models-install\n",
    "python -m pip install Tensorflow/models/research "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e1a65041-5e9b-4f46-a257-7d96ee4215d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# After installation, to confirm is everything is well setuo and can proceed to help us train and and make detections \n",
    "# !cd Tensorflow/models/research && python object_detection/builders/model_builder_tf2_test.py"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20a03949",
   "metadata": {},
   "source": [
    "# Copy Model Config For Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ef51638",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME = \"ssd_mobilenet2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d2fcb62b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Tensorflow/workspace/models\\\\ssd_mobilenet2'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"Tensorflow/workspace/models\\\\\" + MODEL_NAME"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "4d10e8f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "A subdirectory or file Tensorflow\\workspace\\models\\ssd_mobilenet2 already exists.\n"
     ]
    }
   ],
   "source": [
    "## Structure o fthe folder is being created accoring to the documantation in  TENSORFLOW OBJECT DETECTION API\n",
    "!mkdir {\"Tensorflow\\workspace\\models\\\\\" + MODEL_NAME}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "5588309e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copy the config file t the newly created folder , this is where all the adjustment and fine tunning of the model will happen\n",
    "!cp {PRETRAINED_MODEL_PATH+\"\\\\\"+\"ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\"+\"\\\\\"+\"pipeline.config\"} {\"Tensorflow\\workspace\\models\\\\\" + MODEL_NAME}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d9303c9",
   "metadata": {},
   "source": [
    "# Update config for Transfer Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e933a96f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.protos import pipeline_pb2\n",
    "from google.protobuf import text_format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "9cf67189",
   "metadata": {},
   "outputs": [],
   "source": [
    "CONFIG_PATH = MODEL_PATH + \"/\" + MODEL_NAME + \"/pipeline.config\"\n",
    "config = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "\n",
    "# I manually modifified the pipeline.config file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "8e2061c3-45c8-4a6f-8d1d-71369260b438",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUMCLASS = len(labels)\n",
    "BATCHSIZE = 4\n",
    "PATH_TO_PRETRAINED_CHECKPOINT = PRETRAINED_MODEL_PATH + \"/ssd_mobilenet_v2_fpnlite_320x320_coco17_tpu-8\" + \"/\" + \"checkpoint\" + \"/\" + \"ckpt-0\"\n",
    "LABEL_MAP_PATH = ANNOTATION_PATH + \"/label_map.pbtxt\"\n",
    "TRAIN_INPUT_READER_PATH = ANNOTATION_PATH + \"/train.record\"\n",
    "TEST_INPUT_READER_PATH = ANNOTATION_PATH + \"/test.record\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "ca15f696-a293-4aea-a8e4-cc9b21ed2fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipeline_config = pipeline_pb2.TrainEvalPipelineConfig()\n",
    "with tf.io.gfile.GFile(CONFIG_PATH,\"r\") as f:\n",
    "    proto_str = f.read()\n",
    "    text_format.Merge(proto_str,pipeline_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "e70fe95b-9674-4093-8006-4a320b190655",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NUMCLASS' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[187], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m pipeline_config\u001b[38;5;241m.\u001b[39mmodel\u001b[38;5;241m.\u001b[39mssd\u001b[38;5;241m.\u001b[39mnum_classes \u001b[38;5;241m=\u001b[39m \u001b[43mNUMCLASS\u001b[49m\n\u001b[0;32m      2\u001b[0m pipeline_config\u001b[38;5;241m.\u001b[39mtrain_config\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;241m=\u001b[39m BATCHSIZE\n\u001b[0;32m      3\u001b[0m pipeline_config\u001b[38;5;241m.\u001b[39mtrain_config\u001b[38;5;241m.\u001b[39mfine_tune_checkpoint \u001b[38;5;241m=\u001b[39m PATH_TO_PRETRAINED_CHECKPOINT\n",
      "\u001b[1;31mNameError\u001b[0m: name 'NUMCLASS' is not defined"
     ]
    }
   ],
   "source": [
    "# Fine Tiune the model, also set the approrptate path to the train and tes record file\n",
    "pipeline_config.model.ssd.num_classes = NUMCLASS\n",
    "pipeline_config.train_config.batch_size = BATCHSIZE\n",
    "pipeline_config.train_config.fine_tune_checkpoint = PATH_TO_PRETRAINED_CHECKPOINT\n",
    "pipeline_config.train_config.fine_tune_checkpoint_type = \"detection\"\n",
    "pipeline_config.train_input_reader.label_map_path = LABEL_MAP_PATH\n",
    "pipeline_config.train_input_reader.tf_record_input_reader.input_path[:] = [TRAIN_INPUT_READER_PATH]\n",
    "pipeline_config.eval_input_reader[0].label_map_path = LABEL_MAP_PATH\n",
    "pipeline_config.eval_input_reader[0].tf_record_input_reader.input_path[:] = [TEST_INPUT_READER_PATH]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "58481d70-9a7a-41f7-9a5b-d2777235dcb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_text = text_format.MessageToString(pipeline_config)\n",
    "with tf.io.gfile.GFile(CONFIG_PATH,\"wb\") as f:\n",
    "    f.write(config_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03de9b2b",
   "metadata": {},
   "source": [
    "# Train The model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "id": "73396817",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python Tensorflow/models/research/object_detection/model_main_tf2.py --model_dir=Tensorflow/workspace/models/ssd_mobilenet2 --pipeline_config_path=Tensorflow/workspace/models/ssd_mobilenet2/pipeline.config --num_train_steps=1000\n"
     ]
    }
   ],
   "source": [
    "# to print out the command for training the model\n",
    "print(\"\"\"python {}/model_main_tf2.py --model_dir={}/{} --pipeline_config_path={}/{}/pipeline.config --num_train_steps=1000\"\"\".format(APIMODEL_PATH,MODEL_PATH,MODEL_NAME,MODEL_PATH,MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e00b4d04-d79c-489e-9c1b-9f5dad134d64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training happens on in windows shell, To keep track of the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "eea6e8f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow/workspace/models/ssd_mobilenet2\n"
     ]
    }
   ],
   "source": [
    "print(\"{}/{}\".format(MODEL_PATH,MODEL_NAME))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e198a2d1-2a3b-484a-a253-5c90ddb51f16",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ecccd75-d7a9-4b4d-947c-347a43d03630",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Command to use tensorflow board,  to monitor training\n",
    "tensorboard --logdir=Tensorflow/workspace/models/ssd_mobilenet2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8a16a6",
   "metadata": {},
   "source": [
    "# Load Train Model From Checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "dd69cb6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/string_int_label_map.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/eval.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/graph_rewriter.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/input_reader.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/model.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/center_net.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/image_resizer.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/losses.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/post_processing.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/calibration.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/preprocessor.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/faster_rcnn.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/anchor_generator.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/flexible_grid_anchor_generator.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/grid_anchor_generator.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/multiscale_anchor_generator.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/ssd_anchor_generator.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/box_predictor.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/hyperparams.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/fpn.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/ssd.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/box_coder.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/faster_rcnn_box_coder.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/keypoint_box_coder.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/mean_stddev_box_coder.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/square_box_coder.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/matcher.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/argmax_matcher.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/bipartite_matcher.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/region_similarity_calculator.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/pipeline.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/train.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n",
      "C:\\Users\\emryz\\anaconda3\\envs\\tensorflow\\lib\\site-packages\\google\\protobuf\\runtime_version.py:112: UserWarning: Protobuf gencode version 5.28.1 is older than the runtime version 5.28.2 at object_detection/protos/optimizer.proto. Please avoid checked-in Protobuf gencode that can be obsolete.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from object_detection.utils import label_map_util\n",
    "from object_detection.utils import config_util\n",
    "from object_detection.utils import visualization_utils as viz_utils\n",
    "from object_detection.builders import model_builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a7c54261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.checkpoint.checkpoint.CheckpointLoadStatus at 0x226898f38e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "configs = config_util.get_configs_from_pipeline_file(CONFIG_PATH)\n",
    "model_config = configs['model']\n",
    "detection_model = model_builder.build(model_config=model_config, is_training=False)\n",
    "\n",
    "ckpt = tf.compat.v2.train.Checkpoint(model=detection_model)\n",
    "ckpt.restore(os.path.join(CHECKPOINT_PATH, 'ckpt-7')).expect_partial()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8763de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71fd2b5-6552-4222-9c6b-313b990343c5",
   "metadata": {},
   "source": [
    "# test Model on image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "da2fb12c-ad73-4e3a-a6db-3670d2410475",
   "metadata": {},
   "outputs": [],
   "source": [
    "def detection_fn(image):\n",
    "    image, shape = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image,shape)\n",
    "    detections = detection_model.postprocess(prediction_dict, shape)\n",
    "    return detections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "id": "9156b965",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv.imread(\"Tensorflow/workspace/images/test/WIN_20240923_01_49_50_Pro.jpg\")\n",
    "image_display = image.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "id": "53f5d7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tf.cast(image, tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "id": "64cc6066",
   "metadata": {},
   "outputs": [],
   "source": [
    "image, shape = detection_model.preprocess(image[tf.newaxis, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "id": "fb521232-a030-47b8-ad6b-382c72bffe67",
   "metadata": {},
   "outputs": [],
   "source": [
    "detections = detection_fn(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "id": "651a19ee-729d-489a-b3c6-135dbfd4e76f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val = {key:value[0].numpy() for key,value in detections.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "id": "1f205aca-caec-46b0-a89d-5cc87065edd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_max = np.argmax(val[\"detection_scores\"])\n",
    "index_label_max = val[\"detection_classes\"][val_max]\n",
    "label_name = category_index[index_label_max+1][\"name\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "082bd51e-3a5d-49dc-bdb4-8db07434ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# image = cv.imread(\"Tensorflow/workspace/images/test/WIN_20240923_01_49_50_Pro.jpg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "id": "fe53de06-806e-4bbc-8ab9-3533da8944fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Funtion to caption image based on the detection hand signal.\n",
    "\n",
    "def putTextWrapped(image,text):\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    thickness = 2\n",
    "    max_width = image.shape[0] - 20\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    space_width, height = cv.getTextSize(' ', font, font_scale, thickness)\n",
    "    current_line = ''\n",
    "    lines = []\n",
    "    \n",
    "    for word in words:\n",
    "        word_width, _ = cv.getTextSize(word, font, font_scale, thickness)\n",
    "        if cv.getTextSize(current_line,font, font_scale, thickness)[0][0] + word_width[0] + space_width[0] > max_width:\n",
    "            lines.append(current_line)\n",
    "            current_line = word + \" \"\n",
    "        else:\n",
    "            current_line += word + \" \"\n",
    "    \n",
    "    lines.append(current_line)\n",
    "    \n",
    "    x,y = (250, 600)\n",
    "    next_y_rectangle= y - 25\n",
    "    line_height = cv.getTextSize(\"Test\", font, font_scale, thickness)[0][1] + 10\n",
    "    for line in lines[-2:]:\n",
    "        # text_height = cv.getTextSize(line, font, font_scale, thickness)[0][1] + 10\n",
    "        cv.rectangle(image, (int(x), int(next_y_rectangle)), (int(x+700), int(next_y_rectangle + 30)), (255, 255, 255), 30)\n",
    "        next_y_rectangle +=  70\n",
    "        cv.putText(image, line, (x,y), font, 1, (0, 0, 0), 1, 17)\n",
    "        y += line_height + 35\n",
    "    return image\n",
    "\n",
    "cv.imshow('Image with Wrapped Text', putTextWrapped(image_display,label_name))\n",
    "cv.waitKey(0)\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40a64926",
   "metadata": {},
   "source": [
    "# Detect in real time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "5bc75b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for detection\n",
    "@tf.function\n",
    "def detection_fn(image):\n",
    "    image, shape = detection_model.preprocess(image)\n",
    "    prediction_dict = detection_model.predict(image,shape)\n",
    "    detections = detection_model.postprocess(prediction_dict, shape)\n",
    "    return detections\n",
    "\n",
    "# Function to wrap the text with a background \n",
    "def putTextWrapped(image,text):\n",
    "    font = cv.FONT_HERSHEY_SIMPLEX\n",
    "    font_scale = 1\n",
    "    thickness = 2\n",
    "    max_width = image.shape[0] - 20\n",
    "    words = text.split(\" \")\n",
    "    \n",
    "    space_width, height = cv.getTextSize(' ', font, font_scale, thickness)\n",
    "    current_line = ''\n",
    "    lines = []\n",
    "    \n",
    "    for word in words:\n",
    "        word_width, _ = cv.getTextSize(word, font, font_scale, thickness)\n",
    "        if cv.getTextSize(current_line,font, font_scale, thickness)[0][0] + word_width[0] + space_width[0] > max_width:\n",
    "            lines.append(current_line)\n",
    "            current_line = word + \" \"\n",
    "        else:\n",
    "            current_line += word + \" \"\n",
    "    \n",
    "    lines.append(current_line)\n",
    "    \n",
    "    x,y = (120, 380)\n",
    "    next_y_rectangle= y - 25\n",
    "    line_height = cv.getTextSize(\"Test\", font, font_scale, thickness)[0][1] + 10\n",
    "    for line in lines[-2:]:\n",
    "        # text_height = cv.getTextSize(line, font, font_scale, thickness)[0][1] + 10\n",
    "        cv.rectangle(image, (int(x), int(next_y_rectangle)), (int(x+400), int(next_y_rectangle + 30)), (255, 255, 255), 30)\n",
    "        next_y_rectangle +=  70\n",
    "        cv.putText(image, line, (x,y), font, 1, (0, 0, 0), 1, 17)\n",
    "        y += line_height + 35\n",
    "    \n",
    "    return image\n",
    "\n",
    "# Funcion that determines when to caption add new caption to a new line (New detection is added to the line, when a new detection is noticed)\n",
    "def captionImage(detections,prev_text,text_to_display):\n",
    "    val_max = np.argmax(detections[\"detection_scores\"])\n",
    "    index_label_max = detections[\"detection_classes\"][val_max]\n",
    "    label = category_index[index_label_max+1][\"name\"]\n",
    "    if prev_text != label:\n",
    "        text_to_display = text_to_display + \" \" + label\n",
    "        prev_text = label\n",
    "    return prev_text,text_to_display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "0aef16db",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "5cf0c945",
   "metadata": {},
   "outputs": [],
   "source": [
    "category_index = label_map_util.create_category_index_from_labelmap(ANNOTATION_PATH+\"/label_map.pbtxt\",\n",
    "                                                                    use_display_name=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "ddb784cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv.VideoCapture(0)\n",
    "width = int(cap.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv.CAP_PROP_FRAME_HEIGHT))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "id": "39b5f0b0-c035-44a7-8826-8082d466ff62",
   "metadata": {},
   "outputs": [],
   "source": [
    "fourcc = cv.VideoWriter_fourcc(*'mp4v')  # Specify the codec\n",
    "fps = cap.get(cv.CAP_PROP_FPS)\n",
    "out = cv.VideoWriter('out.mp4', fourcc, fps, (width, height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "id": "19936211",
   "metadata": {},
   "outputs": [],
   "source": [
    "prev_text = \"\"\n",
    "text_to_display = \"\"\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    input_np = np.array(frame)\n",
    "    \n",
    "    input_np = np.fliplr(input_np)\n",
    "    \n",
    "    input_tensor = tf.convert_to_tensor(np.expand_dims(input_np,0),dtype=tf.float32)\n",
    "    detections = detection_fn(input_tensor)\n",
    "    num_detections = int(detections.pop(\"num_detections\"))\n",
    "    \n",
    "    detections = {key:value[0,:num_detections].numpy() for key,value in detections.items()}\n",
    "    detections[\"num_detections\"] = num_detections\n",
    "    detections[\"detection_classes\"] = detections[\"detection_classes\"].astype(np.int64)\n",
    "    \n",
    "    label_id_offset = 1\n",
    "    image_np_with_detections = input_np.copy()\n",
    "\n",
    "    prev_text,text_to_display = captionImage(detections,prev_text,text_to_display)\n",
    "    prev_text = prev_text\n",
    "    text_to_display=text_to_display\n",
    "\n",
    "    image_np_with_detections = putTextWrapped(image_np_with_detections,text_to_display)\n",
    "    \n",
    "    \n",
    "    viz_utils.visualize_boxes_and_labels_on_image_array(\n",
    "          image_np_with_detections,\n",
    "          detections['detection_boxes'],\n",
    "          detections['detection_classes'] + label_id_offset,\n",
    "          detections['detection_scores'],\n",
    "          category_index,\n",
    "          use_normalized_coordinates=True,\n",
    "          max_boxes_to_draw=1,\n",
    "          min_score_thresh=.30,\n",
    "          agnostic_mode=False)\n",
    "\n",
    "    \n",
    "    out.write(image_np_with_detections)\n",
    "    cv.imshow('object detection', cv.resize(image_np_with_detections, (1280, 720)))\n",
    "    \n",
    "\n",
    "    if cv.waitKey(25) & 0xFF == ord('q'):\n",
    "        text_to_display = \"\"\n",
    "        prev_text = \"\"\n",
    "        break\n",
    "\n",
    "out.release()\n",
    "cap.release()\n",
    "cv.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a18ea836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca057895",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f86a6885",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tensorflow)",
   "language": "python",
   "name": "tensorflow"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
